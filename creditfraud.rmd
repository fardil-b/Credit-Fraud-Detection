---
title: "creit fraud"
author: "Fardil"
date: "26/08/2020"
output:
  word_document: default
  html_document: default
  pdf_document: default
---
```{r, include=FALSE}
options(tinytex.verbose = TRUE)
```

Loading the data
```{r}
data <- read.csv("creditcard.csv")
# data <- read.csv(file.choose())

```
To see the structure of the data 
```{r}
str(data)
```
The Credit Card Fraud detection Dataset contains transactions made by credit cards in September 2013 by European cardholders. This dataset present transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. 

```{r}
table(data$Class)
```
The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.
```{r}
table(data$Class)/length(data$Class)

```

## First step is always EDA
- to help up see and understand what our data looks like and steps we should further take with regards to our data

# EDA
## Univariate: Distribution
## Bivariate: Correlations 
## Multivariate: Correlations

Let's investigate the variable amount
```{r}
hist(data$Amount)
```
Lot of the transaction are of smaller value but doesn't specified how long tailed it is

```{r}
length(data$Amount)
```

Let slice the data 
Does less than 5 covers lot of our dataset?
```{r}
length(data$Amount[data$Amount < 5])/length(data$Amount) *100

```
Only 23 % of our dataset


What about 50?
```{r}
length(data$Amount[data$Amount < 50])/length(data$Amount) *100
hist(data$Amount[data$Amount < 50])

```

```{r}
length(data$Amount[data$Amount < 100])/length(data$Amount) *100
hist(data$Amount[data$Amount < 100])
```
The bin size is 5, which means that 0-5 has the highest number of transaction



```{r}
length(data$Amount[data$Amount < 200])/length(data$Amount) *100
```
Almost 90% of our transaction

```{r}
hist(data$Amount[data$Amount < 200])

```

Another variable to explore is "time"
These are seconds after how long the next transaction take place after the first one
```{r}
hist(data$Time)
table(data$Time)
```
The hist does not really help in understanding how the variable time function

The varibles Time and Amount does not really link to one another very well
This can be validated by correlation

# Bi-Variate
```{r}
cor(data$Time, data$Amount)

```
Almost neglegible correlation
As Time increases, the amount decreases (-ve correlation)

To justify we could use the correlation plot

```{r}
library(corrplot)
#install.packages("corrplot")

library(caret)
#install.packages("caret")
```
Correlation matrix
```{r}
cor(data)
```
But difficult to understand, to make it more intuitive we use the corrplot()

```{r}
corr_mat <- cor(data)
corrplot(corr_mat, method = "number")
```
```{r}
corrplot(corr_mat, method = "circle")

```


```{r}
caret::featurePlot(x=data[,2:29],y=data[,31])
```

```{r}
head(data)
```
# PCA Example
to understand our data
```{r}
data("mtcars")
prin_comps <- princomp(mtcars)
prin_comps$loadings
```
```{r}
prin_comps$scores
```
# Split data in training and testing sets
```{r}
table(data$Class)
```

Train in one data and test on unseen data

```{r}
library("caret")
set.seed(1) # so that to get the same result
data$Class <-as.factor(data$Class)
train_index <- caret::createDataPartition(y=data$Class, p=0.70,times = 1, list = F)
train <- data[train_index,]
test <- data[-train_index,]

```

# cross validation
5 fold cross validation and repeated 3 times
```{r}
control <- trainControl(method="repeatedcv", number = 5, repeats = 3)

```

# Linear Discriminant Analysis (LDA)
```{r}
lda <- train(Class~.,data=train, method="lda", metric = "Accuracy", trControl= control)

```

```{r}
lda
```
Very high Accuracy could indicate that our model is overfitting the data
Kappa <- how sure we are of the correctness of the model
 
# Logistic regression
glm <<- generalized linear model
```{r}
glm <- train(Class~.,data=train, method="glm", metric = "Accuracy", trControl= control)

```

```{r}
glm
```
Accuracy is almost similar to LDA but the Kappa is has dropped by about 10%


# Support Vector Machines (SVM)
using library (e1071)
```{r}
library (e1071)
```
```{r}
svm <- svm(Class~.,data = train)
```
```{r}
svm
```

# To compare all the models
we use the resamples fucntion from caret
we can compare all of our model and choose the one that fits the best
```{r}
results <- resamples(list(lda=lda,logistic_reg=glm))
```

```{r}
summary(results)
```
The LDA is performing better than the logistic regression
So now we can use the LDA algorithm to make prediction of whether transaction was fraudulent or not
